# Feedforward-Neural-Network
A 3-layer feedforward neural network trained on the MNIST dataset of handwritten digits.

The model retains an input layer of 784 units, a hidden layer of 256 units activated by ReLU, and an output layer activated by softmax in which a discrete probabilty distribution is produced for each input. 

The training process employs standard gradient descent using Root Mean Square Propagation (RMSprop).

# Goal 
The primary objective of this project was to develop an introductory understanding of machine learning concepts and techniques.
